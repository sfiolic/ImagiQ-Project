{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def iid(images, labels, num_users):\n",
    "\n",
    "    num_items = int(len(images)/num_users)\n",
    "    dict_users, all_idxs = {}, [i for i in range(len(images))]\n",
    "    for i in range(num_users):\n",
    "        dict_users[i] = set(np.random.choice(all_idxs, num_items, replace=False))\n",
    "        all_idxs = list(set(all_idxs) - dict_users[i])\n",
    "    return dict_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import skimage.measure\n",
    "\n",
    "def get_dataset(folder, fileLists, labelLists, num, num_users):\n",
    "    \n",
    "    images = np.empty([1,128, 128, 1], dtype = int) \n",
    "    \n",
    "    file_names = fileLists[0:num]\n",
    "    for i in range(len(file_names)):\n",
    "        read_image = cv2.imread(os.path.join(folder,file_names[i]), 0)\n",
    "        read_image = skimage.measure.block_reduce(read_image, (8,8), np.mean)\n",
    "        read_image = np.expand_dims(read_image,axis = (0,3))\n",
    "        images = np.append(images, read_image, axis = 0)\n",
    "        \n",
    "    images = np.uint8(images)\n",
    "    images = np.delete(images, (0), axis = 0)\n",
    "    images = np.swapaxes(images, 2, 3)\n",
    "    images = np.swapaxes(images, 1, 2)\n",
    "\n",
    "    labels = labelLists[0:num]\n",
    "    for i in range(len(labels)):\n",
    "        if sum(labels[i][1::]) >= 1.0:\n",
    "            labels[i][1] = 1.0\n",
    "            labels[i][0] = 0.0\n",
    "    labels = np.delete(labels, np.s_[2::], axis = 1)\n",
    "\n",
    "    user_groups = iid(images, labels, num_users)\n",
    "\n",
    "    return images, labels, user_groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 2, 8, 8)\n",
    "        self.fc1 = nn.Linear(2*8*8, 8)\n",
    "        self.fc2 = nn.Linear(8, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = x.view(-1, x.shape[1]*x.shape[-2]*x.shape[-1])\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_weights(w):\n",
    "\n",
    "    w_avg = copy.deepcopy(w[0])\n",
    "    for key in w_avg.keys():\n",
    "        for i in range(1, len(w)):\n",
    "            w_avg[key] += w[i][key]\n",
    "        w_avg[key] = torch.div(w_avg[key], len(w))\n",
    "    return w_avg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class DatasetSplit(Dataset):\n",
    "    def __init__(self, images, labels, idxs):\n",
    "        self.imageset = images\n",
    "        self.labelset = labels\n",
    "        self.idxs = [int(i) for i in idxs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = self.imageset[self.idxs[item]]\n",
    "        label = self.labelset[self.idxs[item]]\n",
    "        return torch.FloatTensor(image), torch.FloatTensor(label)\n",
    "\n",
    "    \n",
    "    \n",
    "class LocalUpdate(object):\n",
    "    def __init__(self, images, labels, idxs):\n",
    "        self.trainloader, self.testloader = self.train_test(images, labels, list(idxs))\n",
    "        self.device = 'cpu'\n",
    "        self.criterion = nn.CrossEntropyLoss().to(self.device)\n",
    "    \n",
    "    def train_test(self, images, labels, idxs):\n",
    "        idxs_train = idxs[:int(0.9*len(idxs))]\n",
    "        idxs_test = idxs[int(0.9*len(idxs)):]\n",
    "\n",
    "        trainloader = DataLoader(DatasetSplit(images, labels, idxs_train),\n",
    "                                 batch_size=int(len(idxs_train)/2), shuffle=True)\n",
    "        testloader = DataLoader(DatasetSplit(images, labels, idxs_test),\n",
    "                                batch_size=len(idxs_test), shuffle=False)\n",
    "        return trainloader, testloader\n",
    "\n",
    "    def update_weights(self, model, local_ep, lr, global_round):\n",
    "        model.train()\n",
    "        epoch_loss = []\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.5)\n",
    "\n",
    "        for iter in range(local_ep):\n",
    "            batch_loss = []\n",
    "            for batch_idx, (images, labels) in enumerate(self.trainloader):\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                model.zero_grad()\n",
    "                log_probs = model(images)\n",
    "                loss = self.criterion(log_probs, torch.max(labels, 1)[1])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                print('| Global Round : {} | Local Epoch : {} | [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                        global_round, iter, batch_idx * len(images),\n",
    "                        len(self.trainloader.dataset),\n",
    "                        100. * batch_idx / len(self.trainloader), loss.item()))\n",
    "                batch_loss.append(loss.item())\n",
    "            epoch_loss.append(sum(batch_loss)/len(batch_loss))\n",
    "        return model.state_dict(), sum(epoch_loss) / len(epoch_loss)\n",
    "\n",
    "    def inference(self, model):\n",
    "        model.eval()\n",
    "        loss, total, correct = 0.0, 0.0, 0.0\n",
    "        for batch_idx, (images, labels) in enumerate(self.testloader):\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            outputs = model(images)\n",
    "            batch_loss = self.criterion(outputs, torch.max(labels, 1)[1])\n",
    "            loss += batch_loss.item()\n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, user_groups = get_dataset(folder = r'G:/images_001/', \n",
    "                                  fileLists = np.load('fileLists.npy').tolist(), \n",
    "                                  labelLists = np.load('labels_hotEnocded.npy'), \n",
    "                                  num = 300, \n",
    "                                  num_users = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Conv2d(1, 2, kernel_size=(8, 8), stride=(8, 8))\n",
      "  (fc1): Linear(in_features=128, out_features=8, bias=True)\n",
      "  (fc2): Linear(in_features=8, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      " | Global Training Round : 1 |\n",
      "\n",
      "| Global Round : 0 | Local Epoch : 0 | [0/54 (0%)]\tLoss: 1.312659\n",
      "| Global Round : 0 | Local Epoch : 0 | [27/54 (50%)]\tLoss: 1.273576\n",
      "| Global Round : 0 | Local Epoch : 1 | [0/54 (0%)]\tLoss: 0.512606\n",
      "| Global Round : 0 | Local Epoch : 1 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 0 | Local Epoch : 2 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 0 | Local Epoch : 2 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 0 | Local Epoch : 3 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 0 | Local Epoch : 3 | [27/54 (50%)]\tLoss: 0.350299\n",
      "| Global Round : 0 | Local Epoch : 4 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 0 | Local Epoch : 4 | [27/54 (50%)]\tLoss: 0.350299\n",
      "| Global Round : 0 | Local Epoch : 0 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 0 | Local Epoch : 0 | [27/54 (50%)]\tLoss: 0.350299\n",
      "| Global Round : 0 | Local Epoch : 1 | [0/54 (0%)]\tLoss: 0.350299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▊                                                                   | 1/5 [00:00<00:01,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Global Round : 0 | Local Epoch : 1 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 0 | Local Epoch : 2 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 0 | Local Epoch : 2 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 0 | Local Epoch : 3 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 0 | Local Epoch : 3 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 0 | Local Epoch : 4 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 0 | Local Epoch : 4 | [27/54 (50%)]\tLoss: 0.350299\n",
      "\n",
      " | Global Training Round : 2 |\n",
      "\n",
      "| Global Round : 1 | Local Epoch : 0 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 1 | Local Epoch : 0 | [27/54 (50%)]\tLoss: 0.350299\n",
      "| Global Round : 1 | Local Epoch : 1 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 1 | Local Epoch : 1 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 1 | Local Epoch : 2 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 1 | Local Epoch : 2 | [27/54 (50%)]\tLoss: 0.350299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▌                                                  | 2/5 [00:00<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Global Round : 1 | Local Epoch : 3 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 1 | Local Epoch : 3 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 1 | Local Epoch : 4 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 1 | Local Epoch : 4 | [27/54 (50%)]\tLoss: 0.350299\n",
      " \n",
      "Avg Training Stats after 2 global rounds:\n",
      "Training Loss : 0.4360292742649714\n",
      "| Global Round : 1 | Local Epoch : 0 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 1 | Local Epoch : 0 | [27/54 (50%)]\tLoss: 0.350299\n",
      "| Global Round : 1 | Local Epoch : 1 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 1 | Local Epoch : 1 | [27/54 (50%)]\tLoss: 0.387336\n",
      "| Global Round : 1 | Local Epoch : 2 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 1 | Local Epoch : 2 | [27/54 (50%)]\tLoss: 0.350299\n",
      "| Global Round : 1 | Local Epoch : 3 | [0/54 (0%)]\tLoss: 0.387336\n",
      "| Global Round : 1 | Local Epoch : 3 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 1 | Local Epoch : 4 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 1 | Local Epoch : 4 | [27/54 (50%)]\tLoss: 0.350299\n",
      " \n",
      "Avg Training Stats after 2 global rounds:\n",
      "Training Loss : 0.41228181347250936\n",
      "\n",
      " | Global Training Round : 3 |\n",
      "\n",
      "| Global Round : 2 | Local Epoch : 0 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 0 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 1 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 1 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 2 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 2 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 3 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 3 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 4 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 4 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 0 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 0 | [27/54 (50%)]\tLoss: 0.350299\n",
      "| Global Round : 2 | Local Epoch : 1 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 2 | Local Epoch : 1 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 2 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 2 | [27/54 (50%)]\tLoss: 0.350299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████████████▍                                 | 3/5 [00:00<00:00,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Global Round : 2 | Local Epoch : 3 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 2 | Local Epoch : 3 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 4 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 2 | Local Epoch : 4 | [27/54 (50%)]\tLoss: 0.350299\n",
      "\n",
      " | Global Training Round : 4 |\n",
      "\n",
      "| Global Round : 3 | Local Epoch : 0 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 3 | Local Epoch : 0 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 3 | Local Epoch : 1 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 3 | Local Epoch : 1 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 3 | Local Epoch : 2 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 3 | Local Epoch : 2 | [27/54 (50%)]\tLoss: 0.350299\n",
      "| Global Round : 3 | Local Epoch : 3 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 3 | Local Epoch : 3 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 3 | Local Epoch : 4 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 3 | Local Epoch : 4 | [27/54 (50%)]\tLoss: 0.350299\n",
      " \n",
      "Avg Training Stats after 4 global rounds:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████████▏                | 4/5 [00:01<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss : 0.3738128481166703\n",
      "| Global Round : 3 | Local Epoch : 0 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 3 | Local Epoch : 0 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 3 | Local Epoch : 1 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 3 | Local Epoch : 1 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 3 | Local Epoch : 2 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 3 | Local Epoch : 2 | [27/54 (50%)]\tLoss: 0.350299\n",
      "| Global Round : 3 | Local Epoch : 3 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 3 | Local Epoch : 3 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 3 | Local Epoch : 4 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 3 | Local Epoch : 4 | [27/54 (50%)]\tLoss: 0.313262\n",
      " \n",
      "Avg Training Stats after 4 global rounds:\n",
      "Training Loss : 0.3685587618499994\n",
      "\n",
      " | Global Training Round : 5 |\n",
      "\n",
      "| Global Round : 4 | Local Epoch : 0 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 4 | Local Epoch : 0 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 4 | Local Epoch : 1 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 4 | Local Epoch : 1 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 4 | Local Epoch : 2 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 4 | Local Epoch : 2 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 4 | Local Epoch : 3 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 4 | Local Epoch : 3 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 4 | Local Epoch : 4 | [0/54 (0%)]\tLoss: 0.313262\n",
      "| Global Round : 4 | Local Epoch : 4 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 4 | Local Epoch : 0 | [0/54 (0%)]\tLoss: 0.461410\n",
      "| Global Round : 4 | Local Epoch : 0 | [27/54 (50%)]\tLoss: 0.313262\n",
      "| Global Round : 4 | Local Epoch : 1 | [0/54 (0%)]\tLoss: 0.387336\n",
      "| Global Round : 4 | Local Epoch : 1 | [27/54 (50%)]\tLoss: 0.387336\n",
      "| Global Round : 4 | Local Epoch : 2 | [0/54 (0%)]\tLoss: 0.350299\n",
      "| Global Round : 4 | Local Epoch : 2 | [27/54 (50%)]\tLoss: 0.424373\n",
      "| Global Round : 4 | Local Epoch : 3 | [0/54 (0%)]\tLoss: 0.387336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:01<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| Global Round : 4 | Local Epoch : 3 | [27/54 (50%)]\tLoss: 0.387336\n",
      "| Global Round : 4 | Local Epoch : 4 | [0/54 (0%)]\tLoss: 0.424373\n",
      "| Global Round : 4 | Local Epoch : 4 | [27/54 (50%)]\tLoss: 0.350299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = 'cpu'\n",
    "epochs = 5\n",
    "frac = 0.4\n",
    "num_users = 5\n",
    "num_classes = 2\n",
    "print_every = 2\n",
    "\n",
    "global_model = CNN()\n",
    "global_model.to(device)\n",
    "global_model.train()\n",
    "print(global_model)\n",
    "global_weights = global_model.state_dict()\n",
    "\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    local_weights, local_losses = [], []\n",
    "    print(f'\\n | Global Training Round : {epoch+1} |\\n')\n",
    "\n",
    "    global_model.train()\n",
    "    m = max(int(frac * num_users), 1)\n",
    "    idxs_users = np.random.choice(range(num_users), m, replace=False)\n",
    "\n",
    "    for idx in idxs_users:\n",
    "        local_model = LocalUpdate(images, labels, idxs=user_groups[idx])\n",
    "        w, loss = local_model.update_weights(model=copy.deepcopy(global_model),\n",
    "                                             local_ep=5, lr=0.01, global_round=epoch)\n",
    "        local_weights.append(copy.deepcopy(w))\n",
    "        local_losses.append(copy.deepcopy(loss))\n",
    "\n",
    "        # update global weights\n",
    "        global_weights = average_weights(local_weights)\n",
    "\n",
    "        # update global weights\n",
    "        global_model.load_state_dict(global_weights)\n",
    "\n",
    "        loss_avg = sum(local_losses) / len(local_losses)\n",
    "        train_loss.append(loss_avg)\n",
    "\n",
    "        # Calculate avg training accuracy over all users at every epoch\n",
    "        list_loss = []\n",
    "        global_model.eval()\n",
    "        for c in range(num_users):\n",
    "            local_model = LocalUpdate(images, labels, idxs=user_groups[idx])\n",
    "            loss = local_model.inference(model=global_model)\n",
    "            list_loss.append(loss)\n",
    "\n",
    "        # print global training loss after every 'i' rounds\n",
    "        if (epoch+1) % print_every == 0:\n",
    "            print(f' \\nAvg Training Stats after {epoch+1} global rounds:')\n",
    "            print(f'Training Loss : {np.mean(np.array(train_loss))}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
